{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Dense, \n",
    "                                     BatchNormalization, \n",
    "                                     LeakyReLU, \n",
    "                                     Reshape, \n",
    "                                     Conv2DTranspose,\n",
    "                                     Conv2D,\n",
    "                                     Dropout,\n",
    "                                     Flatten)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "from IPython import display as display_console # A command shell for interactive computing in Python.\n",
    "import asyncio\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "IMAGE_SIZE = 8\n",
    "IMAGE_SIZE_O4 = int(IMAGE_SIZE/4)\n",
    "\n",
    "MAX_EPOCHS = 200000\n",
    "BATCH_SIZE = 450\n",
    "\n",
    "NOISE_DIM = 100\n",
    "\n",
    "GENERATOR_LEARNING_RATE = 1e-4\n",
    "JUDGE_LEARNING_RATE = 1e-3\n",
    "\n",
    "RATING_BUTTONS = 5\n",
    "RATING_MEMORY = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator model\n",
    "def generator_model():\n",
    "    # They happen in a linear order\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Add a NN layer with 7*7*256 nodes and no bias\n",
    "    model.add(Dense(IMAGE_SIZE_O4*IMAGE_SIZE_O4*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    # Reshape back into a 2D image with 256 layers (and confirm it was reshaped correctly)\n",
    "    model.add(Reshape((IMAGE_SIZE_O4, IMAGE_SIZE_O4, 256)))\n",
    "\n",
    "    # Convolutional layer; ensures that the output will be the same size\n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    # Another convolutional layer\n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    # Convolution\n",
    "    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    \n",
    "    # Print summary?\n",
    "    print(model.summary())\n",
    "\n",
    "    # Return\n",
    "    return model\n",
    "\n",
    "# Get the model\n",
    "generator = generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates one image from the generator to use as an example\n",
    "def generate_one_image():\n",
    "  noise = tf.random.normal([1, NOISE_DIM])\n",
    "  generated_images = generator(noise, training=False)\n",
    "  return generated_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_model():\n",
    "    # Define model\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Convolutional layer\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[IMAGE_SIZE, IMAGE_SIZE, 1]))\n",
    "    model.add(LeakyReLU()) # ReLU should always come after a convolutional layer\n",
    "    model.add(Dropout(0.3)) # Randomly sets 30% of nodes to 0 during training. Prevents overfitting.\n",
    "\n",
    "    # Another convolution layer, same as above\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Flatten to a 1D vector\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Final step is to convert into a single scalar representing rating\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "# Get the model\n",
    "judge = judge_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_loss(predicted_output, human_output):\n",
    "    cross_entropy = tf.keras.losses.MeanSquaredError()\n",
    "    return cross_entropy(predicted_output, human_output)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    # Generator always wants a value of one (which indicates a high rating)\n",
    "    cross_entropy = tf.keras.losses.MeanSquaredError()\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# Declare optimizers\n",
    "# Judge needs a much faster learning rate to make the most of human feedback\n",
    "generator_optimizer = tf.keras.optimizers.Adam(GENERATOR_LEARNING_RATE)\n",
    "judge_optimizer = tf.keras.optimizers.Adam(JUDGE_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator training step\n",
    "@tf.function\n",
    "def generator_train_step():\n",
    "  \n",
    "    # Give the generator random noise\n",
    "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "      # Generate the fake images for the mini-batch\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      # Judge the output\n",
    "      judge_output = judge(generated_images, training=True)\n",
    "\n",
    "      # Loss\n",
    "      loss = generator_loss(judge_output)\n",
    "\n",
    "      # Get the gradients\n",
    "      gradients = tape.gradient(loss, generator.trainable_variables)\n",
    "\n",
    "      # Optimize\n",
    "      generator_optimizer.apply_gradients(zip(gradients, generator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judge training step\n",
    "@tf.function\n",
    "def judge_train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "      # Train the judge based on the training data we've built\n",
    "      judge_output = judge(images, training=True)\n",
    "\n",
    "      # Loss\n",
    "      loss = judge_loss(judge_output, labels)\n",
    "\n",
    "      # Get the gradients\n",
    "      gradients = tape.gradient(loss, judge.trainable_variables)\n",
    "\n",
    "      # Optimize\n",
    "      judge_optimizer.apply_gradients(zip(gradients, judge.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Define training loop\n",
    "# ====================\n",
    "\n",
    "# Training loop\n",
    "async def train(critical_data):\n",
    "  # In each epoch...\n",
    "  for epoch in range(MAX_EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Do one generator training batch\n",
    "    generator_train_step()\n",
    "\n",
    "    # DEBUG\n",
    "    # print(\n",
    "    #   \"Epoch:\", epoch,\n",
    "    #   \"Image exists:\", critical_data['current_image']!=None,\n",
    "    #   \"user_data:\", len(critical_data['user_data_images']),\n",
    "    #   \"user_data_queue:\", len(critical_data['user_data_images_queue']),\n",
    "    # )\n",
    "\n",
    "    # Total hack, but this sleep is necessary to allow Jupyter widget button presses to work\n",
    "    await asyncio.sleep(0.05)\n",
    "\n",
    "    # Check to see if new examples have been added by the user\n",
    "    if not critical_data['user_data_lock'].locked():\n",
    "      # Acquire lock\n",
    "      await critical_data['user_data_lock'].acquire()\n",
    "\n",
    "      # Move all elements from queue to main dataset\n",
    "      # Images\n",
    "      for entry in critical_data['user_data_images_queue']:\n",
    "        critical_data['user_data_images'].append(entry)\n",
    "      critical_data['user_data_images_queue'] = []\n",
    "\n",
    "      # Labels\n",
    "      for entry in critical_data['user_data_labels_queue']:\n",
    "        critical_data['user_data_labels'].append(entry)\n",
    "      critical_data['user_data_labels_queue'] = []\n",
    "\n",
    "      # Check if a new current_image should be set\n",
    "      if critical_data['current_image'] == None:\n",
    "        critical_data['current_image'] = generate_one_image()\n",
    "\n",
    "      # Release lock\n",
    "      critical_data['user_data_lock'].release()\n",
    "    \n",
    "    # Do judge training step if we have at least one training example\n",
    "    if len(critical_data['user_data_images']) >= 2 and len(critical_data['user_data_labels']) >= 2:\n",
    "      image_tensor = tf.Variable(critical_data['user_data_images'][-RATING_MEMORY:])\n",
    "      image_tensor = tf.reshape(image_tensor, [-1, 8, 8, 1])\n",
    "      label_tensor = tf.Variable(critical_data['user_data_labels'][-RATING_MEMORY:])\n",
    "      label_tensor = tf.reshape(label_tensor, [-1, 1])\n",
    "      judge_train_step(image_tensor, label_tensor)\n",
    "\n",
    "    # Print out epoch data\n",
    "    # print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "# Handle task errors\n",
    "def check_for_errors(task: asyncio.Task) -> None:\n",
    "    try:\n",
    "        task.result()\n",
    "    except asyncio.CancelledError:\n",
    "        pass  # Task cancellation should not be logged as an error\n",
    "    except Exception:\n",
    "        logging.exception('Exception raised by task = %r', task)\n",
    "\n",
    "# ==========\n",
    "# Start task\n",
    "# ==========\n",
    "\n",
    "current_image = None\n",
    "user_data_images_queue = []\n",
    "user_data_labels_queue = []\n",
    "user_data_images = []\n",
    "user_data_labels = []\n",
    "user_data_lock = asyncio.Lock()\n",
    "\n",
    "critical_data = {\n",
    "  'current_image': current_image,\n",
    "  'user_data_images_queue': user_data_images_queue,\n",
    "  'user_data_labels_queue': user_data_labels_queue,\n",
    "  'user_data_images': user_data_images,\n",
    "  'user_data_labels': user_data_labels,\n",
    "  'user_data_lock': user_data_lock,\n",
    "}\n",
    "training_task = asyncio.create_task(train(critical_data))\n",
    "training_task.add_done_callback(check_for_errors)\n",
    "\n",
    "\n",
    "# ==========\n",
    "# User input\n",
    "# ==========\n",
    "\n",
    "# Create all the clickable buttons for the user\n",
    "async def create_buttons():\n",
    "    for i in range(RATING_BUTTONS):\n",
    "        # Calculate the actual number from 0.0 to 1.0 that will be used in the loss function\n",
    "        rating_value = i/(RATING_BUTTONS-1)\n",
    "\n",
    "        # Create and display the button\n",
    "        button = widgets.Button(description=(str(i+1) + \" Star\"))\n",
    "        button.on_click(lambda x, rv=rating_value, r=(i+1): press_rating_button(r, rv))\n",
    "        display(button)\n",
    "\n",
    "# Show image\n",
    "async def show_image(image):\n",
    "    plt.subplot(4, 4, 1)\n",
    "    plt.imshow(image * 127.5 + 127.5, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n",
    "\n",
    "# TODO: Save image button\n",
    "\n",
    "def press_rating_button(rating, rating_value):\n",
    "    button_task = asyncio.create_task(press_rating_button_results(rating, rating_value))\n",
    "    button_task.add_done_callback(check_for_errors)\n",
    "\n",
    "async def press_rating_button_results(rating, rating_value):\n",
    "    # Clear console\n",
    "    display_console.clear_output(wait=True)\n",
    "\n",
    "    # Print a holdover text\n",
    "    print(\"You rated that image\", rating, \"star.\")\n",
    "\n",
    "    # Save this result to the user data queue\n",
    "    await critical_data['user_data_lock'].acquire()\n",
    "    critical_data['user_data_images_queue'].append(critical_data['current_image'])\n",
    "    critical_data['user_data_labels_queue'].append(rating_value)\n",
    "    critical_data['current_image'] = None\n",
    "    critical_data['user_data_lock'].release()\n",
    "\n",
    "    # Move on to next image\n",
    "    await next_image()\n",
    "\n",
    "# Wait for an image for the human to rate and then set up the image and buttons\n",
    "async def next_image():\n",
    "    while (True):\n",
    "      if critical_data['current_image'] == None:\n",
    "          # If no image has been posted yet, sleep to wait for a new one\n",
    "          print(\"No image; sleeping...\") # DEBUG\n",
    "          await asyncio.sleep(1)\n",
    "          continue\n",
    "      else:\n",
    "          # Clear current display\n",
    "          display_console.clear_output(wait=True)\n",
    "\n",
    "          # Show the image and give the user the rating buttons\n",
    "          await show_image(critical_data['current_image'])\n",
    "          await create_buttons()\n",
    "\n",
    "          # End the while loop so we can receive user input\n",
    "          break\n",
    "\n",
    "# Start user input\n",
    "button_task = asyncio.create_task(next_image())\n",
    "button_task.add_done_callback(check_for_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
